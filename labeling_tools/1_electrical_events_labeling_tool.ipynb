{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tool to identify the electrical component events in CREAM\n",
    "\n",
    "<p> This jupyter notebook was used to label the electrical appliance events in the data. <b> This is the first notebook in the labeling pipeline of CREAM. </b> </p>\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Instructions for labeling</h3>\n",
    "    <p>Go through each day separately, by chaning the day of interest below. After you are done with a day, reset the corresponding cells. \n",
    "        <b>Please be aware, that every click into the figures gets recorded</b>. In case of errors (e.g. unintentional wrong click), you can execute the cell below each figure to remove the last click from the record </p>\n",
    "\n",
    "<p> To save the events clicked, please use the corresponding cell below the figures.</p>\n",
    "\n",
    "<p> <b> An event is defined as a 5 Ampere jump in the current signal. </b> </p>\n",
    "<p> For turn-on events click at the foot of the event (before it increases) and for switch-off events select the peak of the event before the current drops </p> This helps to identify on- and off-events.\n",
    "    \n",
    "<p> <b> In case you are done with labeling everything (i.e. all days), you can uncomment and execute the last cell of the notebook to merge the individual files with the labels per hour into one overall file. </b> </p>\n",
    " \n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import scipy.interpolate\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "# Add project path to path for import\n",
    "project_path = os.path.abspath(\"..\")\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "# Add module path to path for import\n",
    "module_path = os.path.abspath(\"../data_utility/data_utility.py\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from data_utility import CREAM_Day # class to work with a day of the CREAM Dataset\n",
    "\n",
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "%load_ext autoreload\n",
    "%autoreload 2 # Reload all modules every time before executing the Python code typed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_CHUNK_SIZE_MINUTES = 2\n",
    "SAMPLING_FREQUENCY = 6400\n",
    "FILE_LENGTH_MINUTES = 60\n",
    "SIGNAL_CHUNK_SIZE_SAMPLES = SAMPLING_FREQUENCY * FILE_LENGTH_MINUTES  * SIGNAL_CHUNK_SIZE_MINUTES  # 2 minute chunks\n",
    "TIME_PER_DATAPOINT = 1 / SAMPLING_FREQUENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Function for deleting erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_last_click(event_dictionary):\n",
    "    \"\"\"Deletes the last click from every key in the event_dictionary.\"\"\"\n",
    "    for k, v in event_dictionary.items():\n",
    "        event_dictionary[k] = v[:-1]\n",
    "    \n",
    "    return event_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>//TODO</h3>\n",
    "    <p>Please specify the path to the main-folder of \"CREAM\". </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = os.path.abspath(os.path.join(\"..\", \"..\", \"Datasets\", \"CREAM\", \"CREAM\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>//TODO</h3>\n",
    "    <p>Please specify the path to the main folder where the labels should be saved. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVE_LOCATION = os.path.abspath(os.path.join(\"..\", \"..\", \"Datasets\", \"CREAM\", \"tmp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Labelings\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h3>In case of labeling errros: </h3>\n",
    "    <p>After each \"hourly\" cell, you can execute the code to delete last click. Just execute the cell</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h3>//ToDo</h3>\n",
    "    <p>After you are done with a day, select the new day by altering the <b> CURRENT_DAY </b> variable and reset the notebook </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DAY = \"2018-08-24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_path = os.path.join(PATH_TO_DATA, CURRENT_DAY)\n",
    "day_save_path = os.path.join(PATH_TO_SAVE_LOCATION, CURRENT_DAY)\n",
    "\n",
    "if not os.path.isdir(day_save_path): # in case the folder to store the labels of the day has not been created yet\n",
    "    os.mkdir(day_save_path)\n",
    "\n",
    "current_CREAM_day = CREAM_Day(cream_day_location=day_path) \n",
    "\n",
    "files_of_day = current_CREAM_day.files  # all files from this day\n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "def onclick(event):\n",
    "    \"\"\"\n",
    "    Function to be executed in case of a click event at a figure.\n",
    "    \"\"\"\n",
    "    event_dictionary[\"Filename\"].append(files_of_day[current_hour_index])\n",
    "    event_dictionary[\"Timestamp\"].append(math.floor(event.xdata))\n",
    "    event_dictionary[\"Amplitude\"].append(math.floor(event.ydata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <p>In case the interactive mode of the figures is not working, reexecute the import cell. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Hour  (6:00 - 7:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 0\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "# event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hour  (7:00 - 8:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 1\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hour (8:00 - 9:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 2\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hour (9:00 - 10:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 3\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hour (10:00 - 11:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 4\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hour (11:00 - 12:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 5\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hour (12:00 - 13:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 6\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hour (13:00 - 14:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 7\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hour (14:00 - 15:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 8\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hour (15:00 - 16:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 9\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hour (16:00 - 17:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 10\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Hour (18:00 - 19:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 11\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Hour (19:00 - 20:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 12\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Hour (19:00 - 20:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 13\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Hour (20:00 - 21:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 14\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                                    timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "\n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Hour (21:00 - 22:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# DO NOT DELETE, needs to be loaded twice!\n",
    "%matplotlib notebook  \n",
    "\n",
    "event_dictionary = {\n",
    "    \"Filename\": [],\n",
    "    \"Timestamp\": [],\n",
    "    \"Amplitude\": []\n",
    "}\n",
    "\n",
    "current_hour_index = 15\n",
    "current_day_path = os.path.join(day_path, files_of_day[current_hour_index])\n",
    "voltage, current = current_CREAM_day.load_file(current_CREAM_day.files[current_hour_index], return_noise=False)\n",
    "start_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].Start_timestamp\n",
    "end_timestamp_file = current_CREAM_day.files_metadata_df.iloc[current_hour_index].End_timestamp\n",
    "\n",
    "whole_current_signal = current  # get the current signal of the whole file\n",
    "number_of_chunks = int(len(whole_current_signal) / SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "all_current_signal_chunks = np.array_split(whole_current_signal,number_of_chunks)\n",
    "\n",
    "# plot 2 minute chunks\n",
    "for chunk_number, current_signal_chunk in enumerate(all_current_signal_chunks):\n",
    "    start_timestamp_chunk = start_timestamp_file + timedelta(minutes=int(SIGNAL_CHUNK_SIZE_MINUTES * chunk_number)) #compute the start of the chunk\n",
    "    end_timestamp_chunk = start_timestamp_chunk + timedelta(minutes=SIGNAL_CHUNK_SIZE_MINUTES)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)   \n",
    "    fig.canvas.mpl_connect('button_press_event', onclick) #append event to figure\n",
    "    \n",
    "    xticks = np.arange(len(current_signal_chunk)) + (chunk_number * SIGNAL_CHUNK_SIZE_SAMPLES)\n",
    "    ax.plot(xticks, current_signal_chunk, markersize=0.1) #plot, only hours\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=90) #rotate the xlabels\n",
    "     \n",
    "    if np.max(current_signal_chunk) < 1:\n",
    "           ax.set_ylim([-6,6])\n",
    " \n",
    "    plt.title(str(start_timestamp_chunk) + \" - \" + str(end_timestamp_chunk))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Made an error?</h3>\n",
    "    <p>Uncomment and execute the following cell to delete the last click.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TO DELETE WRONG DATA - uncomment if needed\n",
    "#event_dictionary = delete_last_click(event_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Save the labels</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(day_save_path, str(str(current_CREAM_day.day_date) + \"_hour-\" + str(current_hour_index) + \".csv\"))\n",
    "event_df = pd.DataFrame(event_dictionary)\n",
    "event_df[\"Timestamp\"] = event_df[\"Timestamp\"].apply(lambda index: start_timestamp_file + \n",
    "                                               timedelta(seconds=(index * TIME_PER_DATAPOINT)))  \n",
    "event_df.to_csv(save_path, sep=\";\", header=True, index=False, encoding=\"utf-8\", decimal=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Are all hours/chunks of the day labeled? Did you save the data?</h3>\n",
    "    <p>Please jump to the top of the notebook and select the next day, by changing the <b>CURRENT_DAY</b> variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the labeling procedure (i.e. all days done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h1> Merge the single day files if you have labeled everything </h1>\n",
    "    <p> Uncomment the following cell, to load the individual files (the per hour file created before in the labeling process) and merge them into a final file. \n",
    "        This final file is then save at the data location. The file is uncommented to prevent from accidentially running this code.</p>\n",
    "    <p> <b> The code also creates the \"Event_Type\" column, indicating \"On\" or \"Off\" events by using the amplitude information from the labeling </b> </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"ALL_DAYS = [\"2018-08-23\" , \"2018-08-24\" , \"2018-08-25\",  \"2018-08-26\" , \"2018-08-27\" , \"2018-08-28\" ,\n",
    "\"2018-08-29\", \"2018-08-30\", \"2018-08-31\", \"2018-09-01\", \"2018-09-02\" , \"2018-09-03\" ,  \"2018-09-04\" ,\n",
    "\"2018-09-05\", \"2018-09-06\", \"2018-09-07\", \"2018-09-08\" , \"2018-09-09\" , \"2018-09-10\", \"2018-09-11\", \"2018-09-12\" \n",
    "\"2018-09-13\" ,\"2018-09-14\" ,\"2018-09-15\" ,  \"2018-09-16\", \"2018-09-17\", \"2018-09-18\",\"2018-09-19\"  , \"2018-09-20\" ,\n",
    "\"2018-09-21\" , \"2018-09-22\" ,  \"2018-09-23\" ,\"2018-09-24\" ,\"2018-09-25\" ,\"2018-09-26\" , \"2018-09-27\", \"2018-09-28\" ,\n",
    "\"2018-09-29\" , \"2018-09-30\" , \"2018-10-01\" ,\"2018-10-02\" , \"2018-10-03\" ,\"2018-10-04\", \"2018-10-05\" , \"2018-10-06\" ,\n",
    "\"2018-10-07\", \"2018-10-08\"]\n",
    "\n",
    "PATH_TO_SAVE_LOCATION = os.path.abspath(os.path.join(\"..\", \"..\", \"Datasets\", \"CREAM\",  ))\n",
    "\n",
    "# Load all the individually labeled files for all days\n",
    "all_labeled_files = []\n",
    "for day in ALL_DAYS:\n",
    "    day_path = os.path.join(PATH_TO_SAVE_LOCATION, day)\n",
    "    labeled_files = glob.glob(os.path.join(day_path, \"*.csv\"))\n",
    "    all_labeled_files.extend(labeled_files)\n",
    "\n",
    "all_labeled_dfs = []\n",
    "import pdb\n",
    "for f in all_labeled_files:\n",
    "    print(os.path.basename(f))\n",
    "        \n",
    "    event_df = pd.read_csv(f, sep=\";\", encoding=\"utf-8\", decimal=\".\")\n",
    "    all_labeled_dfs.append(event_df)\n",
    "    \n",
    "pdb.set_trace()\n",
    "component_df = pd.concat(all_labeled_dfs)\n",
    "\n",
    "timezone = current_CREAM_day.get_datetime_from_filepath(current_CREAM_day.files[0]).tzinfo #get the correct timzone\n",
    "component_df.Timestamp = component_df.Timestamp.apply(pd.Timestamp)\n",
    "component_df.Timestamp = component_df.Timestamp.dt.tz_localize(timezone)\n",
    "component_df.sort_values(\"Timestamp\", inplace=True)\n",
    "\n",
    "pdb.set_trace()\n",
    "# Add the \"Event_Type\" column and fill it\n",
    "# This is done by computing the differences between consecutive rows and the following rows.\n",
    "# We need to discard the last event since its event type cannot be computed due to the lack of a follow up event.\n",
    "# Since it's only a relatively small number, we discard them to ensure the data integrity.\n",
    "\n",
    "component_df.Amplitude = component_df.Amplitude.apply(pd.to_numeric)\n",
    "\n",
    "diff = np.diff(component_df.Amplitude.values)\n",
    "\n",
    "component_df = component_df.iloc[0:-1]  # discard the last event, as explained above\n",
    "component_df['Event_Type'] = diff\n",
    "\n",
    "component_df = component_df[component_df.Event_Type != 0]  # discard 0 diffs\n",
    "\n",
    "component_df.Event_Type = component_df.Event_Type.apply(lambda x: \"On\" if x > 0 else \"Off\")\n",
    "pdb.set_trace()\n",
    "# Adjust the timestamp, to make them match the product and maintenance event timestamps with respect to the timezone offset\n",
    "\n",
    "\n",
    "component_df.to_csv(os.path.join(PATH_TO_DATA, \"raw_coffee_maker_logs\", \"raw_component_events.csv\"), index=False)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
